---
layout: post
title: 2025-2-14-Ubuntu 20.04 安装 docker 并配置 Nvidia
date: 2025-2-14
tags: Linux-Docker
---

## Ubuntu 20.04 安装 docker

### 1. 配置 docker 安装源

检查卸载老版本docker

ubuntu下自带了docker的库，不需要添加新的源。 但是ubuntu自带的docker版本太低，需要先卸载旧的再安装新的。

```sh
root@ai-node:~# sudo apt-get remove docker docker-engine docker.io containerd runc
```

更新软件包

```sh
root@ai-node:~# sudo apt update
root@ai-node:~# sudo apt upgrade
```

安装 docker 在 Ubuntu 上依赖的一些软件包

```sh
root@ai-node:~# sudo apt-get install ca-certificates curl gnupg lsb-release
```

添加Docker官方GPG密钥，使用阿里云提供的

```sh
root@ai-node:~# sudo curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
```

添加Docker的软件源

```sh
root@ai-node:~# sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
```

### 2. 安装 docker

使用 `apt-cache madison` 命令来查看可用的 Docker 版本

```sh
root@ai-node:~# sudo apt-cache madison docker-ce
root@ai-node:~# sudo apt-cache madison docker-ce-cli
```

如：

```sh
root@ai-node:~# apt-cache madison docker-ce-cli |grep 20.10
docker-ce-cli | 5:20.10.24~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.23~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.22~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.21~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.20~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.19~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.18~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.17~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.16~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.15~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.14~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
docker-ce-cli | 5:20.10.13~3-0~ubuntu-jammy | http://mirrors.aliyun.com/docker-ce/linux/ubuntu  jammy/stable amd64 Packages
```

安装指定版本 docker

```sh
root@ai-node:~# sudo apt-get install -y docker-ce=5:20.10.20~3-0~ubuntu-jammy docker-ce-cli=5:20.10.20~3-0~ubuntu-jammy
```

### 3. 配置 docker

```sh
root@ai-node:~# systemctl status docker
● docker.service - Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2025-02-14 01:52:13 UTC; 4min 8s ago
TriggeredBy: ● docker.socket
       Docs: https://docs.docker.com
   Main PID: 11771 (dockerd)
      Tasks: 35
     Memory: 29.8M
        CPU: 511ms
     CGroup: /system.slice/docker.service
             └─11771 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.414678424Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.414713440Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.414729680Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.434455030Z" level=info msg="Loading containers: start."
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.722914079Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.873515868Z" level=info msg="Loading containers: done."
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.889432690Z" level=info msg="Docker daemon" commit=03df974 graphdriver(s)=overlay2 version=20.10.20
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.889565948Z" level=info msg="Daemon has completed initialization"
Feb 14 01:52:13 ai-node systemd[1]: Started Docker Application Container Engine.
Feb 14 01:52:13 ai-node dockerd[11771]: time="2025-02-14T01:52:13.917210631Z" level=info msg="API listen on /run/docker.sock"
```

```sh
root@ai-node:~# vim /etc/docker/daemon.json
{
  "data-root": "/data/lib/docker",
  "registry-mirrors": [
      "https://6130e0dd.cf-workers-docker-io-upw.pages.dev",
      "https://docker-mirror-proxy.zhenmourener.workers.dev/"
  ],
  "insecure-registries": [
      "example.com:5000"
  ],
  "live-restore": true,
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "10"
  }
}
```

重新加载 docker

```sh
root@ai-node:~# systemctl daemon-reload 
root@ai-node:~# systemctl restart docker
```

### 4. 安装 docker-compose

```sh
root@ai-node:~# curl -L "https://github.com/docker/compose/releases/dwnload/v2.24.6/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
root@ai-node:~# chmod +x /usr/local/bin/docker-compose
root@ai-node:~# docker-compose --version
Docker Compose version v2.24.6
```


## Nvidia 驱动

### 1. 安装驱动

如果没有安装请看如下命令

添加 NVIDIA 驱动源

```sh
root@ai-node:~# sudo add-apt-repository ppa:graphics-drivers/ppa
root@ai-node:~# sudo apt update
```

使用 `ubuntu-drivers` 工具查找适合的驱动版本

```sh
root@ai-node:~# sudo apt install -y ubuntu-drivers-common
ubuntu-drivers devices
```

从输出中找到推荐的驱动版本（通常标记为 `recommended`）。例如，如果推荐的驱动版本是 `nvidia-driver-560`，则运行以下命令安装

```sh
root@ai-node:~# sudo apt install -y nvidia-driver-560
```

Nouveau 是一个开源的 NVIDIA 驱动，可能会与官方驱动冲突。可以通过以下命令禁用它

```sh
root@ai-node:~# sudo apt install dkms
root@ai-node:~# sudo bash -c "echo 'blacklist nouveau' > /etc/modprobe.d/blacklist-nouveau.conf"
root@ai-node:~# sudo bash -c "echo 'options nouveau modeset=0' >> /etc/modprobe.d/blacklist-nouveau.conf"
root@ai-node:~# sudo update-initramfs -u
```

安装完成后，重启系统以使驱动生效

```sh
root@ai-node:~# sudo reboot
```

```sh
root@ai-node:~# nvidia-smi 
Fri Feb 14 02:18:21 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     Off |   00000000:41:00.0 Off |                    0 |
|  0%   28C    P8             12W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A40                     Off |   00000000:61:00.0 Off |                    0 |
|  0%   26C    P8             12W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A40                     Off |   00000000:A1:00.0 Off |                    0 |
|  0%   27C    P8             12W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

### 2. 安装 Nvidia-docker

添加Nvidia官方的源，然后使用APT安装NVIDIA Container Toolkit

```sh
root@ai-node:~# sudo curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
&& curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
```

```sh
root@ai-node:~# sudo apt-get update
root@ai-node:~# sudo apt-get install -y nvidia-container-toolkit
```

为Docker配置NVIDIA Container Runtime

```sh
root@ai-node:~# sudo nvidia-ctk runtime configure --runtime=docker
INFO[0000] Loading config from /etc/docker/daemon.json  
INFO[0000] Wrote updated config to /etc/docker/daemon.json 
INFO[0000] It is recommended that docker daemon be restarted.
root@ai-node:~# sudo systemctl restart docker
root@ai-node:~# cat /etc/docker/daemon.json 
{
    "data-root": "/data/lib/docker",
    "exec-opts": [
        "native.cgroupdriver=systemd"
    ],
    "insecure-registries": [
        "example.com:5000"
    ],
    "live-restore": true,
    "log-driver": "json-file",
    "log-opts": {
        "max-file": "10",
        "max-size": "100m"
    },
    "registry-mirrors": [
        "https://6130e0dd.cf-workers-docker-io-upw.pages.dev",
        "https://docker-mirror-proxy.zhenmourener.workers.dev/"
    ],
    "runtimes": {
        "nvidia": {
            "args": [],
            "path": "nvidia-container-runtime"
        }
    }
}
```

验证

```sh
root@ai-node:~# sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi
Unable to find image 'ubuntu:latest' locally
latest: Pulling from library/ubuntu
5a7813e071bf: Pulling fs layer 
latest: Pulling from library/ubuntu
5a7813e071bf: Pulling fs layer 
latest: Pulling from library/ubuntu
5a7813e071bf: Pull complete 
Digest: sha256:72297848456d5d37d1262630108ab308d3e9ec7ed1c3286a32fe09856619a782
Status: Downloaded newer image for ubuntu:latest
Fri Feb 14 02:32:58 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     Off |   00000000:41:00.0 Off |                    0 |
|  0%   30C    P8             21W /  300W |       4MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A40                     Off |   00000000:61:00.0 Off |                    0 |
|  0%   26C    P8             12W /  300W |       4MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A40                     Off |   00000000:A1:00.0 Off |                    0 |
|  0%   29C    P8             21W /  300W |       4MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

### 3. 测试验证

创建一个简单的 CUDA 程序，例如 `hello_cuda.cu`

```sh
root@ai-node:~# cat hello_cuda.cu 
#include <iostream>
#include <chrono>
#include <thread>

__global__ void hello_cuda() {
    printf("Hello from GPU! Thread id: %d\n", threadIdx.x);
}

int main() {
    while (true) {
        // 启动一个 GPU 核函数
        hello_cuda<<<1, 10>>>();

        // 等待 GPU 完成任务
        cudaDeviceSynchronize();

        std::cout << "Hello from CPU!" << std::endl;

        // 让 CPU 休眠一段时间，再次调用 CUDA 核函数
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
    return 0;
}
```

```sh
root@ai-node:~# apt -y install nvidia-cuda-toolkit
root@ai-node:~# nvcc -o hello_cuda hello_cuda.cu
root@ai-node:~# ./hello_cuda
```

查看显卡信息

```sh
root@ai-node:~# nvidia-smi 
Fri Feb 14 03:39:55 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     Off |   00000000:41:00.0 Off |                    0 |
|  0%   35C    P0             73W /  300W |     299MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A40                     Off |   00000000:61:00.0 Off |                    0 |
|  0%   27C    P8             12W /  300W |       4MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A40                     Off |   00000000:A1:00.0 Off |                    0 |
|  0%   30C    P8             22W /  300W |       4MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A     21998      C   ./hello_cuda                                  290MiB |
+-----------------------------------------------------------------------------------------+
```

Docker 运行测试

```sh
root@ai-node:~# cat Dockerfile 
# 使用 NVIDIA CUDA 基础镜像
FROM nvidia/cuda:11.0.3-devel-ubuntu20.04

# 将当前工作目录下的代码复制到容器内
COPY hello_cuda.cu /workspace/hello_cuda.cu

# 设置工作目录
WORKDIR /workspace

# 编译 CUDA 程序
RUN nvcc hello_cuda.cu -o hello_cuda

# 运行程序
CMD ./hello_cuda
```

```sh
root@ai-node:~# docker build -t hello-cuda .
# 容器使用所有可用的 GPU
root@ai-node:~# docker run -it --rm --name hello_cuda hello-cuda:latest 

# 容器内的程序会同时使用 GPU 0 和 GPU 1
root@ai-node:~# docker run -it --rm --name hello_cuda --gpus '"device=0,1"' hello-cuda:latest
```

### 4. k8s 调用方法

NVIDIA Device Plugin 是 Kubernetes 生态系统中管理 GPU 资源的关键组件。它通过与 Kubernetes 的深度集成，实现了 GPU 资源的自动发现、调度和分配，使得 GPU 资源能够像 CPU 和内存一样被 Kubernetes 管理

```sh
root@ai-node:/data/k8s-app/nvidia-plugin# cat nvidia-device-plugin-daemonset.yaml 
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nvidia-device-plugin-config
  namespace: kube-system
data:
  nvidia-device-plugin-config.yaml: |
    version: v1
    flags:
      migStrategy: mixed
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 10  # 虚拟资源的副本数量，假如你有3块实体的卡，这里配置副本10，那么总虚拟资源就是30
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  annotations:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  template:
    metadata:
      labels:
        name: nvidia-device-plugin-ds
    spec:
      containers:
      - command:
        - /usr/bin/nvidia-device-plugin
        - --config-file
        - /etc/nvidia-device-plugin/nvidia-device-plugin-config.yaml
        env:
        - name: FAIL_ON_INIT_ERROR
          value: "false"
        - name: MIG_STRATEGY
          value: mixed
        image: registry.cn-hangzhou.aliyuncs.com/tianxiang_app/k8s-device-plugin:v0.14.0 
        imagePullPolicy: IfNotPresent
        name: nvidia-device-plugin-ctr
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /var/lib/kubelet/device-plugins
          name: device-plugin
        - mountPath: /etc/nvidia-device-plugin
          name: nvidia-device-plugin-config
      dnsPolicy: ClusterFirst
      nodeSelector:
        nvidia.com/gpu.present: "true"
      priorityClassName: system-node-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      tolerations:
      - operator: Exists
      #- effect: NoSchedule
      #  key: nvidia.com/gpu
      #  operator: Exists
      volumes:
      - hostPath:
          path: /var/lib/kubelet/device-plugins
          type: ""
        name: device-plugin
      - configMap:
          defaultMode: 420
          name: nvidia-device-plugin-config
        name: nvidia-device-plugin-config
  updateStrategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
```
如果启动后报错如下
```sh
root@ai-node:/data/k8s-app/nvidia-plugin# kubectl apply -f nvidia-device-plugin-daemonset.yaml
root@ai-node:/data/k8s-app/nvidia-plugin# kubectl -n kube-system logs -f nvidia-device-plugin-daemonset-hqdpc 
I0217 10:06:13.989717       1 main.go:154] Starting FS watcher.
I0217 10:06:13.989875       1 main.go:161] Starting OS watcher.
I0217 10:06:13.990060       1 main.go:176] Starting Plugins.
I0217 10:06:13.990083       1 main.go:234] Loading configuration.
I0217 10:06:13.990665       1 main.go:242] Updating config with default resource matching patterns.
W0217 10:06:13.991212       1 rm.go:121] mig-strategy="mixed" is only supported with NVML
W0217 10:06:13.991221       1 rm.go:122] NVML not detected: could not load NVML library: libnvidia-ml.so.1: cannot open shared object file: No such file or directory
```

解决办法如下，添加 `"default-runtime": "nvidia",`设置 nvidia-container-runtime 为默认的低级运行时

```sh
root@ai-node:/data/k8s-app/nvidia-plugin# cat /etc/docker/daemon.json 
{
    "data-root": "/data/lib/docker",
    "exec-opts": [
        "native.cgroupdriver=systemd"
    ],
    "insecure-registries": [
        "example.com:5000"
    ],
    "live-restore": true,
    "log-driver": "json-file",
    "log-opts": {
        "max-file": "10",
        "max-size": "100m"
    },
    "registry-mirrors": [
        "https://6130e0dd.cf-workers-docker-io-upw.pages.dev",
        "https://docker-mirror-proxy.zhenmourener.workers.dev/"
    ],
    "default-runtime": "nvidia",
    "runtimes": {
        "nvidia": {
            "args": [],
            "path": "nvidia-container-runtime"
        }
    }
}
```

查看节点信息发现GPU资源已经显示出来了

```sh
root@ai-node:/data/k8s-app/nvidia-plugin# kubectl describe node ai-node
Addresses:
  InternalIP:  172.16.246.122
  Hostname:    ai-node
Capacity:
  cpu:                256
  ephemeral-storage:  917546988Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1056563328Ki
  nvidia.com/gpu:     30
  pods:               110
Allocatable:
  cpu:                256
  ephemeral-storage:  845611302741
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1056460928Ki
  nvidia.com/gpu:     30
  pods:               110

Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                1100m (0%)  0 (0%)
  memory             240Mi (0%)  340Mi (0%)
  ephemeral-storage  0 (0%)      0 (0%)
  hugepages-1Gi      0 (0%)      0 (0%)
  hugepages-2Mi      0 (0%)      0 (0%)
  nvidia.com/gpu     0           0
Events: 
```

