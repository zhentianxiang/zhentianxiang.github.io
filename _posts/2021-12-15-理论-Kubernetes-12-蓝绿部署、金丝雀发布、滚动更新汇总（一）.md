---
layout: post
title: 理论-Kubernetes-12-蓝绿部署、金丝雀发布、滚动更新汇总(一)
date: 2021-12-15
tags: 理论-Kubernetes
---

## 一、前言

转载自https://blog.csdn.net/weixin_38320674/article/details/105828889

## 二、kubernetes多种发布方式概述

### 1. 金丝雀发布（又称灰度发布、灰度更新）

金丝雀发布一般是先发1台机器，或者一个小比例，例如2%的服务器，主要做流量验证用，也称为金丝雀 (Canary) 测试，国内常称灰度测试。以前旷工下矿前，会先放一只金丝雀进去用于探测洞里是否有有毒气体，看金丝雀能否活下来，金丝雀发布由此得名。简单的金丝雀测试一般通过手工测试验证，复杂的金丝雀测试需要比较完善的监控基础设施配合，通过监控指标反馈，观察金丝雀的健康状况，作为后续发布或回退的依据。如果金丝测试通过，则把剩余的 V1 版本全部升级为 V2 版本。如果金丝雀测试失败，则直接回退金丝雀，发布失败。


人话理解就是：本来我Deployement有3个副本，也就是replicas，镜像是nginx:1.24.1，然后我修改了一下镜像1.24.2，副本数量不变，然后就会启动新的镜像pod，此时就会有一个pod率先探测能否正常的创建，如果可以，那么其余2个pod依次创建


而灰度和金丝雀其实就是，1和2之间有个1.5，这个1.5也就是pod更新的时候会有一个理想主义上的金丝雀去探测到底能不能更新新版镜像。所以灰度也就是，黑与白之间，而之间就是灰色的。

### 2. 滚动更新

在金丝雀发布基础上的进一步优化改进，是一种自动化程度较高的发布方式，用户体验比较平滑，是目前成熟型技术组织所采用的主流发布方式。一次滚动式发布一般由若干个发布批次组成，每批的数量一般是可以配置的（可以通过发布模板定义）。例如，第一批1台（金丝雀），第二批10%，第三批 50%，第四批100%。每个批次之间留观察间隔，通过手工验证或监控反馈确保没有问题再发下一批次，所以总体上滚动式发布过程是比较缓慢的 (其中金丝雀的时间一般会比后续批次更长，比如金丝雀10 分钟，后续间隔 2分钟)。


原理就是：通过replicas控制器控制的，控制有几个副本，启动几个副本，那么哪个东西来绝对的副本确确实实能启动到预期的效果呢，就是maxSurge（控制副本向预定的数量更新）和maxUnavailable（最多几个不可用）。


人话理解就是：首先pending 然后然后creating然后running，剩下的在terminating，然后creating然后running，而且更新途中不会使服务发生间断。

### 3. 蓝绿部署

一些应用程序只需要部署一个新版本，并需要立即切到这个版本。因此，我们需要执行蓝/绿部署。在进行蓝/绿部署时，应用程序的一个新副本（绿）将与现有版本（蓝）一起部署。然后更新应用程序的入口/路由器以切换到新版本（绿）。然后，您需要等待旧（蓝）版本来完成所有发送给它的请求，但是大多数情况下，应用程序的流量将一次更改为新版本；Kubernetes不支持内置的蓝/绿部署。目前最好的方式是创建新的部署，然后更新应用程序的服务（如service）以指向新的部署；蓝绿部署是不停老版本，部署新版本然后进行测试，确认OK后将流量逐步切到新版本。蓝绿部署无需停机，并且风险较小。

人话理解就是：我上线服务，不是上线一个，而是上线两版本的服务，一个service资源里面写两个服务的lable，我用哪个放开哪个，不用的#注释掉，然后测试发布，有问题再换回来。把#注释掉的lable放开，把放开的注释掉，然后这样service不就又重新解析到后端服了哎


## 三、Deployment定义

Deployment实现更新逻辑和更新策略是借助于ReplicaSet完成的，Deployment这种资源对象可以定义的字段有哪些，通过如下命令查看：

```sh
[root@k8s-kubersphere nginx-replicas]# kubectl explain deploy
KIND:     Deployment
VERSION:  apps/v1

DESCRIPTION:
     Deployment enables declarative updates for Pods and ReplicaSets.

FIELDS:
   apiVersion	<string>
     APIVersion defines the versioned schema of this representation of an
     object. Servers should convert recognized schemas to the latest internal
     value, and may reject unrecognized values. More info:
     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources

   kind	<string>
     Kind is a string value representing the REST resource this object
     represents. Servers may infer this from the endpoint the client submits
     requests to. Cannot be updated. In CamelCase. More info:
     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds

   metadata	<Object>
     Standard object metadata.

   spec	<Object>
     Specification of the desired behavior of the Deployment.

   status	<Object>
     Most recently observed status of the Deployment.
```

```sh
[root@k8s-kubersphere nginx-replicas]# kubectl explain deploy.spec
KIND:     Deployment
VERSION:  apps/v1

RESOURCE: spec <Object>

DESCRIPTION:
     Specification of the desired behavior of the Deployment.

     DeploymentSpec is the specification of the desired behavior of the
     Deployment.

FIELDS:
   minReadySeconds	<integer>
     Minimum number of seconds for which a newly created pod should be ready
     without any of its container crashing, for it to be considered available.
     Defaults to 0 (pod will be considered available as soon as it is ready)

   paused	<boolean>   #暂停，当我们更新的时候创建pod先暂停，不是立即更新
     Indicates that the deployment is paused.

   progressDeadlineSeconds	<integer>
     The maximum time in seconds for a deployment to make progress before it is
     considered to be failed. The deployment controller will continue to process
     failed deployments and a condition with a ProgressDeadlineExceeded reason
     will be surfaced in the deployment status. Note that progress will not be
     estimated during the time a deployment is paused. Defaults to 600s.

   replicas	<integer>   #保留的历史版本数，默认是10个
     Number of desired pods. This is a pointer to distinguish between explicit
     zero and not specified. Defaults to 1.

   revisionHistoryLimit	<integer>
     The number of old ReplicaSets to retain to allow rollback. This is a
     pointer to distinguish between explicit zero and not specified. Defaults to
     10.

   selector	<Object> -required-
     Label selector for pods. Existing ReplicaSets whose pods are selected by
     this will be the ones affected by this deployment. It must match the pod
     template's labels.


   strategy	<Object> # 更新策略，支持的滚动更新策略
     The deployment strategy to use to replace existing pods with new ones.

   template	<Object> -required-
     Template describes the pods that will be created.
```

```sh
[root@k8s-kubersphere nginx-replicas]# kubectl explain deploy.spec.strategy
KIND:     Deployment
VERSION:  apps/v1

RESOURCE: strategy <Object>

DESCRIPTION:
     The deployment strategy to use to replace existing pods with new ones.

     DeploymentStrategy describes how to replace existing pods with new ones.

FIELDS:    # 滚动更新参数
   rollingUpdate	<Object>
     Rolling update config params. Present only if DeploymentStrategyType =
     RollingUpdate.

   type	<string>  # 支持两种更新，Recreate和RollingUpdate
     Type of deployment. Can be "Recreate" or "RollingUpdate". Default is
     RollingUpdate.
```
```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl explain deploy.spec.strategy.rollingUpdate
KIND:     Deployment
VERSION:  apps/v1

RESOURCE: rollingUpdate <Object>

DESCRIPTION:
     Rolling update config params. Present only if DeploymentStrategyType =
     RollingUpdate.

     Spec to control the desired behavior of rolling update.

FIELDS:
   maxSurge	<string>  #我们更新的过程当中最多允许超出的指定的目标副本数有几个它有两种取值方式，第一种直接给定数量
第二种根据百分比，百分比表示原本是5个，最多可以超出20%，那就允许多一个最多可以超过40%，那就允许多两个
     The maximum number of pods that can be scheduled above the desired number
     of pods. Value can be an absolute number (ex: 5) or a percentage of desired
     pods (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number
     is calculated from percentage by rounding up. Defaults to 25%. Example:
     when this is set to 30%, the new ReplicaSet can be scaled up immediately
     when the rolling update starts, such that the total number of old and new
     pods do not exceed 130% of desired pods. Once old pods have been killed,
     new ReplicaSet can be scaled up further, ensuring that total number of pods
     running at any time during the update is at most 130% of desired pods.

   maxUnavailable	<string>  #最多允许几个不可用
     The maximum number of pods that can be unavailable during the update. Value
     can be an absolute number (ex: 5) or a percentage of desired pods (ex:
     10%). Absolute number is calculated from percentage by rounding down. This
     can not be 0 if MaxSurge is 0. Defaults to 25%. Example: when this is set
     to 30%, the old ReplicaSet can be scaled down to 70% of desired pods
     immediately when the rolling update starts. Once new pods are ready, old
     ReplicaSet can be scaled down further, followed by scaling up the new
     ReplicaSet, ensuring that the total number of pods available at all times
     during the update is at least 70% of desired pods.
```

## 四、Deployment部署应用的更新策略演示

假设有5个副本，最多一个不可用，就表示最少有4个可用，deployment是一个三级结构，deployment控制replicaset，replicaset控制pod，用deployment创建一个pod

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx
  namespace: my-nginx
  labels:
    app: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: my-nginx
        image: nginx:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
      restartPolicy: Always
```

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n my-nginx
NAME                        READY   STATUS    RESTARTS   AGE
my-nginx-7fddfdc897-lxsnt   1/1     Running   0          25m
my-nginx-7fddfdc897-xf8kb   1/1     Running   0          25m
[root@k8s-kubersphere nginx-replicas]# kubectl get deployments.apps -n my-nginx
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
my-nginx   2/2     2            2           25m
```

接下来我们修改yaml中的 replicas 值为3，然后apply

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n my-nginx
NAME                        READY   STATUS    RESTARTS   AGE
my-nginx-7fddfdc897-cd8fr   1/1     Running   0          5m25s
my-nginx-7fddfdc897-lxsnt   1/1     Running   0          4h14m
my-nginx-7fddfdc897-xf8kb   1/1     Running   0          4h14m
```

发现pod数量变为3个，然后查看deployment详细信息

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl describe deployments.apps -n my-nginx
Name:                   my-nginx
Namespace:              my-nginx
CreationTimestamp:      Wed, 15 Dec 2021 18:06:40 +0800
Labels:                 app=myapp
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=myapp
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge   #默认的更新策略rollingUpdate，最多允许多25%个pod，25%表示不足一个，可以补一个
Pod Template:
  Labels:  app=myapp
  Containers:
   my-nginx:
    Image:        nginx:latest
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  <none>
NewReplicaSet:   my-nginx-7fddfdc897 (3/3 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  6m20s  deployment-controller  Scaled up replica set my-nginx-7fddfdc897 to 3
  ```

### 1. 案例演示（金丝雀发布）

  监测更新过程，输入命令动态查看pod更新状况，然后新开一个窗口修改replicas值为4，然后apply发现，旧的pod没有发生改变（删除），从而又创建一个新的pod，这就是默认的RollingUpdate策略的效果

  ```#!/bin/sh
[root@k8s-kubersphere ~]# kubectl get pods -n my-nginx -w
NAME                        READY   STATUS    RESTARTS   AGE
my-nginx-7fddfdc897-cd8fr   1/1     Running   0          8m51s
my-nginx-7fddfdc897-lxsnt   1/1     Running   0          4h18m
my-nginx-7fddfdc897-xf8kb   1/1     Running   0          4h18m
my-nginx-7fddfdc897-vcz6h   0/1     Pending   0          0s
my-nginx-7fddfdc897-vcz6h   0/1     Pending   0          0s
my-nginx-7fddfdc897-vcz6h   0/1     ContainerCreating   0          0s
my-nginx-7fddfdc897-vcz6h   0/1     ContainerCreating   0          1s
my-nginx-7fddfdc897-vcz6h   1/1     Running             0          2s
```

然后继续动态查看pod，打开另外一个标签，修改yaml里面的image镜像，然后再apply

```yaml
[root@k8s-kubersphere nginx-replicas]# vim deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx
  namespace: my-nginx
  labels:
    app: myapp
spec:
  replicas: 4
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: my-nginx
        image: nginx:1.21.4
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
      restartPolicy: Always
```

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl apply -f deploy.yaml
deployment.apps/my-nginx configured
```

切换到之前的窗口，发现更新镜像之后，创建一个新的pod就立即暂停，这就是我们说的金丝雀发布，也可以说灰度发布

![](/images/posts/Linux-Kubernetes/k8s_replicas/3.png)

```#!/bin/sh
[root@k8s-kubersphere ~]# kubectl get pods -n my-nginx -w
NAME                        READY   STATUS    RESTARTS   AGE
my-nginx-7fddfdc897-cd8fr   1/1     Running   0          8m51s
my-nginx-7fddfdc897-lxsnt   1/1     Running   0          4h18m
my-nginx-7fddfdc897-xf8kb   1/1     Running   0          4h18m
my-nginx-7fddfdc897-vcz6h   0/1     Pending   0          0s       # 新创建的pod，
my-nginx-7fddfdc897-vcz6h   0/1     Pending   0          0s
my-nginx-7fddfdc897-vcz6h   0/1     ContainerCreating   0          0s  # 创建中
my-nginx-7fddfdc897-vcz6h   0/1     ContainerCreating   0          1s
my-nginx-7fddfdc897-vcz6h   1/1     Running             0          2s   # 新pod running
my-nginx-7d878c8b66-x2jfg   0/1     Pending             0          0s   # 然后其余的3个pod，依次更新为新的pod
my-nginx-7d878c8b66-x2jfg   0/1     Pending             0          0s
my-nginx-7fddfdc897-vcz6h   1/1     Terminating         0          4m42s
my-nginx-7d878c8b66-gv6nl   0/1     Pending             0          0s
my-nginx-7d878c8b66-x2jfg   0/1     ContainerCreating   0          0s
my-nginx-7d878c8b66-gv6nl   0/1     Pending             0          0s
my-nginx-7d878c8b66-gv6nl   0/1     ContainerCreating   0          0s
my-nginx-7fddfdc897-vcz6h   1/1     Terminating         0          4m43s
my-nginx-7d878c8b66-gv6nl   0/1     ContainerCreating   0          2s
my-nginx-7d878c8b66-x2jfg   0/1     ContainerCreating   0          2s
my-nginx-7fddfdc897-vcz6h   0/1     Terminating         0          4m44s
my-nginx-7fddfdc897-vcz6h   0/1     Terminating         0          4m45s
my-nginx-7fddfdc897-vcz6h   0/1     Terminating         0          4m45s
my-nginx-7d878c8b66-gv6nl   1/1     Running             0          31s
my-nginx-7fddfdc897-cd8fr   1/1     Terminating         0          14m
my-nginx-7d878c8b66-tmpzf   0/1     Pending             0          0s
my-nginx-7d878c8b66-tmpzf   0/1     Pending             0          0s
my-nginx-7d878c8b66-tmpzf   0/1     ContainerCreating   0          0s
my-nginx-7fddfdc897-cd8fr   1/1     Terminating         0          14m
my-nginx-7d878c8b66-tmpzf   0/1     ContainerCreating   0          2s
my-nginx-7fddfdc897-cd8fr   0/1     Terminating         0          14m
my-nginx-7d878c8b66-x2jfg   1/1     Running             0          37s
my-nginx-7fddfdc897-xf8kb   1/1     Terminating         0          4h23m
my-nginx-7d878c8b66-7tfhf   0/1     Pending             0          0s
my-nginx-7d878c8b66-7tfhf   0/1     Pending             0          0s
my-nginx-7d878c8b66-7tfhf   0/1     ContainerCreating   0          1s
my-nginx-7fddfdc897-cd8fr   0/1     Terminating         0          14m
my-nginx-7fddfdc897-cd8fr   0/1     Terminating         0          14m
my-nginx-7fddfdc897-xf8kb   1/1     Terminating         0          4h23m
my-nginx-7d878c8b66-7tfhf   0/1     ContainerCreating   0          2s
my-nginx-7fddfdc897-xf8kb   0/1     Terminating         0          4h23m
my-nginx-7fddfdc897-xf8kb   0/1     Terminating         0          4h23m
my-nginx-7fddfdc897-xf8kb   0/1     Terminating         0          4h23m
my-nginx-7d878c8b66-tmpzf   1/1     Running             0          33s
my-nginx-7fddfdc897-lxsnt   1/1     Terminating         0          4h24m
my-nginx-7fddfdc897-lxsnt   1/1     Terminating         0          4h24m
my-nginx-7fddfdc897-lxsnt   0/1     Terminating         0          4h24m
my-nginx-7fddfdc897-lxsnt   0/1     Terminating         0          4h24m
my-nginx-7fddfdc897-lxsnt   0/1     Terminating         0          4h24m
my-nginx-7d878c8b66-7tfhf   1/1     Running             0          40s
```

当然，我们也可以陈述式修改镜像，推荐使用陈述时，因为你声明式修改yaml，资源更新之后的回滚，yaml不会同步信息，还是回滚之前的信息,这是就不好判断yaml中的信息和deployment中的信息一致不一致，后续也希望修改资源的的时候可以`kubectl edit deployment`这样的相对来说也是比较正确的

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl set image -n my-nginx deployment/my-nginx my-nginx=nginx:1.21.4 --record
deployment.apps/my-nginx image updated
[root@k8s-kubersphere nginx-replicas]# kubectl rollout status deployment/my-nginx -n my-nginx
Waiting for deployment "my-nginx" rollout to finish: 2 out of 4 new replicas have been updated...
Waiting for deployment "my-nginx" rollout to finish: 2 out of 4 new replicas have been updated...
Waiting for deployment "my-nginx" rollout to finish: 2 out of 4 new replicas have been updated...
Waiting for deployment "my-nginx" rollout to finish: 3 out of 4 new replicas have been updated...
Waiting for deployment "my-nginx" rollout to finish: 3 out of 4 new replicas have been updated...
Waiting for deployment "my-nginx" rollout to finish: 3 out of 4 new replicas have been updated...
Waiting for deployment "my-nginx" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "my-nginx" rollout to finish: 1 old replicas are pending termination...
deployment "my-nginx" successfully rolled out
```

查看replicas控制器发现有两个了

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl get replicasets.apps -n my-nginx
NAME                  DESIRED   CURRENT   READY   AGE
my-nginx-7d878c8b66   4         4         4       4m48s
my-nginx-7fddfdc897   0         0         0       4h27m
```

**回滚操作**

如果发现刚才升级的这个版本有问题可以回滚,查看当前有哪几个版本

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl rollout history deployment -n my-nginx
deployment.apps/my-nginx
REVISION  CHANGE-CAUSE
1         <none>
2         <none>
[root@k8s-kubersphere nginx-replicas]# kubectl get replicasets.apps -n my-nginx -o wide
NAME                  DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         SELECTOR
my-nginx-7d878c8b66   4         4         4       8m53s   my-nginx     nginx:1.21.4   app=myapp,pod-template-hash=7d878c8b66
my-nginx-7fddfdc897   0         0         0       4h31m   my-nginx     nginx:latest   app=myapp,pod-template-hash=7fddfdc897
```

回滚replicas

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl rollout  undo deployment -n my-nginx my-nginx
deployment.apps/my-nginx rolled back
```

查看已经回滚到上一版

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n my-nginx
NAME                        READY   STATUS    RESTARTS   AGE
my-nginx-7fddfdc897-2m4m7   1/1     Running   0          18s
my-nginx-7fddfdc897-7dhwh   1/1     Running   0          22s
my-nginx-7fddfdc897-pdmrg   1/1     Running   0          22s
my-nginx-7fddfdc897-sghd4   1/1     Running   0          19s
[root@k8s-kubersphere nginx-replicas]# kubectl get replicasets.apps -n my-nginx -o wide
NAME                  DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         SELECTOR
my-nginx-7d878c8b66   0         0         0       12m     my-nginx     nginx:1.21.4   app=myapp,pod-template-hash=7d878c8b66
my-nginx-7fddfdc897   4         4         4       4h35m   my-nginx     nginx:latest   app=myapp,pod-template-hash=7fddfdc897
```

再次查看更新次数已经是第3版了，而这个第3版其实也就是第1版

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl rollout history deployment -n my-nginx
deployment.apps/my-nginx
REVISION  CHANGE-CAUSE
2         <none>
3         <none>
```

### 2. 案例演示（滚动更新）

其实就是修改image镜像，然后动态查看pod状态，发现pending表示正在进行调度，ContainerCreating表示正在创建一个pod，running表示运行一个pod，running起来一个pod之后再Terminating（停掉）一个pod，以此类推，直到所有pod完成滚动升级


上面已经演示过，就不再多说，然后这里说一下修改maxSurge和maxUnavailable用来控制滚动更新的更新策略

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx
  namespace: my-nginx
  labels:
    app: myapp
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate: # 更新pod不会停止
      maxSurge: 1      # 生成一个新的pod，也就是要升级镜像的pod，往后的pod会Terminating，然后ContainerCreating最后running
      maxUnavailable: 0  # 最多0个不可用，也就是不可能pod变为0，当前replicas数量是4，最低也是4，最后还是原来的4个pod，但是pod的镜像已经滚动更新
  replicas: 4
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: my-nginx
        image: nginx:1.21.4 这里还继续用这版镜像，因为刚才已经在命令行回滚过第3版了，也就是latest版的镜像
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
      restartPolicy: Always
```
首先另开一个窗口，动态查看pod变化

```#!/bin/sh
[root@k8s-kubersphere ~]# kubectl get pods -n my-nginx -w
NAME                        READY   STATUS    RESTARTS   AGE
my-nginx-7fddfdc897-66z5d   1/1     Running   0          6m11s
my-nginx-7fddfdc897-brzqb   1/1     Running   0          6m8s
my-nginx-7fddfdc897-nnj56   1/1     Running   0          6m16s
my-nginx-7fddfdc897-r58h6   1/1     Running   0          6m13s




my-nginx-7d878c8b66-f5kgx   0/1     Pending   0          0s  # 这里发现调度了一个新的pod，也就是滚动更新的1.21.4版本的镜像
my-nginx-7d878c8b66-f5kgx   0/1     Pending   0          0s
my-nginx-7d878c8b66-f5kgx   0/1     ContainerCreating   0          0s  # 创建1.21.4版镜像pod
my-nginx-7d878c8b66-f5kgx   0/1     ContainerCreating   0          2s
my-nginx-7d878c8b66-f5kgx   1/1     Running             0          3s  # 启动1.21.4版镜像pod
my-nginx-7fddfdc897-brzqb   1/1     Terminating         0          7m17s  # 然后再停止一个pod，4个pod中的第2个pod
my-nginx-7d878c8b66-s8dkl   0/1     Pending             0          0s  # 启动一个新的1.21.4镜像pod，也就是4个副本中的第2个pod，依此类推
my-nginx-7d878c8b66-s8dkl   0/1     Pending             0          0s
my-nginx-7d878c8b66-s8dkl   0/1     ContainerCreating   0          0s
my-nginx-7fddfdc897-brzqb   1/1     Terminating         0          7m17s
my-nginx-7fddfdc897-brzqb   0/1     Terminating         0          7m18s
my-nginx-7d878c8b66-s8dkl   0/1     ContainerCreating   0          2s
my-nginx-7d878c8b66-s8dkl   1/1     Running             0          3s
my-nginx-7fddfdc897-r58h6   1/1     Terminating         0          7m25s
my-nginx-7d878c8b66-jfjcd   0/1     Pending             0          0s
my-nginx-7d878c8b66-jfjcd   0/1     Pending             0          0s
my-nginx-7d878c8b66-jfjcd   0/1     ContainerCreating   0          0s
my-nginx-7fddfdc897-r58h6   1/1     Terminating         0          7m25s
my-nginx-7d878c8b66-jfjcd   0/1     ContainerCreating   0          1s
my-nginx-7fddfdc897-r58h6   0/1     Terminating         0          7m27s
my-nginx-7fddfdc897-brzqb   0/1     Terminating         0          7m22s
my-nginx-7fddfdc897-brzqb   0/1     Terminating         0          7m22s
my-nginx-7d878c8b66-jfjcd   1/1     Running             0          2s
my-nginx-7fddfdc897-66z5d   1/1     Terminating         0          7m25s
my-nginx-7d878c8b66-z4znb   0/1     Pending             0          0s
my-nginx-7d878c8b66-z4znb   0/1     Pending             0          0s
my-nginx-7d878c8b66-z4znb   0/1     ContainerCreating   0          0s
my-nginx-7fddfdc897-66z5d   1/1     Terminating         0          7m26s
my-nginx-7fddfdc897-r58h6   0/1     Terminating         0          7m28s
my-nginx-7fddfdc897-r58h6   0/1     Terminating         0          7m28s
my-nginx-7d878c8b66-z4znb   0/1     ContainerCreating   0          1s
my-nginx-7fddfdc897-66z5d   0/1     Terminating         0          7m27s
my-nginx-7d878c8b66-z4znb   1/1     Running             0          2s
my-nginx-7fddfdc897-nnj56   1/1     Terminating         0          7m32s
my-nginx-7fddfdc897-nnj56   1/1     Terminating         0          7m33s
my-nginx-7fddfdc897-nnj56   0/1     Terminating         0          7m34s
my-nginx-7fddfdc897-nnj56   0/1     Terminating         0          7m35s
my-nginx-7fddfdc897-nnj56   0/1     Terminating         0          7m35s
my-nginx-7fddfdc897-66z5d   0/1     Terminating         0          7m39s
my-nginx-7fddfdc897-66z5d   0/1     Terminating         0          7m39s
```

### 3. 案例演示（蓝绿部署）

首先，先把蓝绿yaml都启动一下，看一下效果什么样

- lan.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
  namespace: blue-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: v1
  template:
    metadata:
     labels:
       app: myapp
       version: v1
    spec:
      containers:
      - name: myapp
        image: janakiramm/myapp:v1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
```
- lv.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v2
  namespace: blue-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: v2
  template:
    metadata:
     labels:
       app: myapp
       version: v2
    spec:
      containers:
      - name: myapp
        image: janakiramm/myapp:v2
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
```

- service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-lan
  namespace: blue-green
  labels:
     app: myapp
     version: v1
spec:
   type: NodePort
   ports:
   - port: 80
     nodePort: 30062
     name: http
   selector:
     app: myapp
     version: v1
```
启动一下yaml文件
```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl apply -f lan.yaml
deployment.apps/myapp-v1 created
[root@k8s-kubersphere nginx-replicas]# kubectl apply -f lv.yaml
deployment.apps/myapp-v2 created
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n blue-green
NAME                        READY   STATUS              RESTARTS   AGE
myapp-v1-8448d48797-fp5n5   0/1     ContainerCreating   0          8s
myapp-v1-8448d48797-jg4j9   0/1     ContainerCreating   0          8s
myapp-v1-8448d48797-wbz7d   0/1     ContainerCreating   0          8s
myapp-v2-5c8fbf549f-2p8t9   0/1     ContainerCreating   0          5s
myapp-v2-5c8fbf549f-6hfhp   0/1     ContainerCreating   0          5s
myapp-v2-5c8fbf549f-882x7   0/1     ContainerCreating   0          5s
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n blue-green -o wide
NAME                        READY   STATUS    RESTARTS   AGE     IP              NODE              NOMINATED NODE   READINESS GATES
myapp-v1-8448d48797-fp5n5   1/1     Running   0          3m52s   10.100.85.211   k8s-node01        <none>           <none>
myapp-v1-8448d48797-jg4j9   1/1     Running   0          3m52s   10.100.46.6     k8s-kubersphere   <none>           <none>
myapp-v1-8448d48797-wbz7d   1/1     Running   0          3m52s   10.100.58.244   k8s-node02        <none>           <none>
myapp-v2-5c8fbf549f-2p8t9   1/1     Running   0          3m49s   10.100.46.36    k8s-kubersphere   <none>           <none>
myapp-v2-5c8fbf549f-6hfhp   1/1     Running   0          3m49s   10.100.85.197   k8s-node01        <none>           <none>
myapp-v2-5c8fbf549f-882x7   1/1     Running   0          3m49s   10.100.58.245   k8s-node02        <none>           <none>
[root@k8s-kubersphere nginx-replicas]# kubectl apply -f service.yaml
service/myapp-lan created
[root@k8s-kubersphere nginx-replicas]# kubectl get svc -n blue-green
NAME        TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
myapp-lan   NodePort   10.97.89.118   <none>        80:30062/TCP   7s
[root@k8s-kubersphere nginx-replicas]# kubectl get endpoints -n blue-green myapp-lan
NAME        ENDPOINTS                                          AGE
myapp-lan   10.100.46.6:80,10.100.58.244:80,10.100.85.211:80   16s
```
浏览器查看lan pod服务效果

![](/images/posts/Linux-Kubernetes/k8s_replicas/1.png)

然后修改一下service lable，使其匹配到lv pod 服务

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-lan
  namespace: blue-green
  labels:
     app: myapp
     version: v2
spec:
   type: NodePort
   ports:
   - port: 80
     nodePort: 30062
     name: http
   selector:
     app: myapp
     version: v2
```

启动一下service yaml，查看浏览器访问结果

![](/images/posts/Linux-Kubernetes/k8s_replicas/2.png)

### 4. 实例演示（滚动更新蓝绿服务）

首先我们可以把lv的服务给停掉了，因为我们可以指直接使用lan的yaml进行滚动更新了

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl delete -f lv.yaml
deployment.apps "myapp-v2" deleted
```

修改一下lan yaml文件，添加滚动更新策略

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
  namespace: blue-green
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: v1
  template:
    metadata:
     labels:
       app: myapp
       version: v1
    spec:
      containers:
      - name: myapp
        #image: janakiramm/myapp:v1
        image: janakiramm/myapp:v2          # 因为现在lan的服务还在运行，我们修改一下镜像，因为要升级，升级为lv
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
```
启动yaml，最好另开一个窗口动观测一下效果，别忘了 serivce 也要修改回来

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl apply -f lan.yaml
deployment.apps/myapp-v1 configured
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n blue-green -o wide
NAME                        READY   STATUS    RESTARTS   AGE   IP              NODE              NOMINATED NODE   READINESS GATES
myapp-v1-69d5787956-54vdf   1/1     Running   0          19s   10.100.46.18    k8s-kubersphere   <none>           <none>
myapp-v1-69d5787956-6dwkd   1/1     Running   0          22s   10.100.58.246   k8s-node02        <none>           <none>
myapp-v1-69d5787956-f46md   1/1     Running   0          24s   10.100.85.213   k8s-node01        <none>           <none>
# 查看已经有了新的一版deployment
[root@k8s-kubersphere nginx-replicas]# kubectl rollout history deployment -n blue-green
deployment.apps/myapp-v1
REVISION  CHANGE-CAUSE
1         <none>
2         <none>
[root@k8s-kubersphere nginx-replicas]# kubectl get replicasets.apps -n blue-green
NAME                  DESIRED   CURRENT   READY   AGE
myapp-v1-69d5787956   3         3         3       5m50s
myapp-v1-8448d48797   0         0         0       29m
[root@k8s-kubersphere nginx-replicas]# kubectl get replicasets.apps -n blue-green -o wide
NAME                  DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES                SELECTOR
myapp-v1-69d5787956   3         3         3       8m21s   myapp        janakiramm/myapp:v2   app=myapp,pod-template-hash=69d5787956,version=v1
myapp-v1-8448d48797   0         0         0       31m     myapp        janakiramm/myapp:v1   app=myapp,pod-template-hash=8448d48797,version=v1
[root@k8s-kubersphere nginx-replicas]# vim service.yaml
[root@k8s-kubersphere nginx-replicas]# kubectl apply -f service.yaml
service/myapp-lan configured
```

另外一个窗口动态pod滚动效果

```#!/bin/sh
[root@k8s-kubersphere nginx-replicas]# kubectl get pods -n blue-green -w
NAME                        READY   STATUS    RESTARTS   AGE
myapp-v1-8448d48797-fp5n5   1/1     Running   0          22m
myapp-v1-8448d48797-jg4j9   1/1     Running   0          22m
myapp-v1-8448d48797-wbz7d   1/1     Running   0          22m
myapp-v1-69d5787956-f46md   0/1     Pending   0          0s
myapp-v1-69d5787956-f46md   0/1     Pending   0          0s
myapp-v1-69d5787956-f46md   0/1     ContainerCreating   0          0s
myapp-v1-69d5787956-f46md   0/1     ContainerCreating   0          1s
myapp-v1-69d5787956-f46md   1/1     Running             0          2s
myapp-v1-8448d48797-fp5n5   1/1     Terminating         0          23m
myapp-v1-69d5787956-6dwkd   0/1     Pending             0          0s
myapp-v1-69d5787956-6dwkd   0/1     Pending             0          0s
myapp-v1-69d5787956-6dwkd   0/1     ContainerCreating   0          0s
myapp-v1-8448d48797-fp5n5   1/1     Terminating         0          23m
myapp-v1-69d5787956-6dwkd   0/1     ContainerCreating   0          2s
myapp-v1-8448d48797-fp5n5   0/1     Terminating         0          23m
myapp-v1-69d5787956-6dwkd   1/1     Running             0          3s
myapp-v1-8448d48797-wbz7d   1/1     Terminating         0          23m
myapp-v1-69d5787956-54vdf   0/1     Pending             0          0s
myapp-v1-69d5787956-54vdf   0/1     Pending             0          0s
myapp-v1-69d5787956-54vdf   0/1     ContainerCreating   0          0s
myapp-v1-8448d48797-fp5n5   0/1     Terminating         0          23m
myapp-v1-8448d48797-wbz7d   1/1     Terminating         0          23m
myapp-v1-8448d48797-wbz7d   0/1     Terminating         0          23m
myapp-v1-69d5787956-54vdf   0/1     ContainerCreating   0          2s
myapp-v1-8448d48797-fp5n5   0/1     Terminating         0          23m
myapp-v1-8448d48797-fp5n5   0/1     Terminating         0          23m
myapp-v1-69d5787956-54vdf   1/1     Running             0          2s
myapp-v1-8448d48797-jg4j9   1/1     Terminating         0          23m
myapp-v1-8448d48797-jg4j9   1/1     Terminating         0          23m
myapp-v1-8448d48797-jg4j9   0/1     Terminating         0          23m
myapp-v1-8448d48797-jg4j9   0/1     Terminating         0          23m
myapp-v1-8448d48797-jg4j9   0/1     Terminating         0          23m
myapp-v1-8448d48797-wbz7d   0/1     Terminating         0          23m
myapp-v1-8448d48797-wbz7d   0/1     Terminating         0          23m
```

再次查看浏览器效果图

![](/images/posts/Linux-Kubernetes/k8s_replicas/2.png)

其实不管金丝雀发布还是滚动更新，只是要你明白这个pod更新镜像的一个形式，我上去直接卡卡一顿操作，修改yaml文件image镜像照样没问题，我回滚打大不了再修改回去，只要你记得住，有保留就行。而蓝绿发布只是更人性化的方便观看效果而已
